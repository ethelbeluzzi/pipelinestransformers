{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcY45NSDYbl7"
      },
      "source": [
        "# Usando Pipelines - Hugging Face\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse notebook possui diversos Pipelines prontos para uso. Antes de cada uso, existe uma explicação de qual é sua utilidade.\n",
        "\n",
        "\n",
        "*   A **função pipeline** é a função mais básica do Transformers - conectando um modelo com as etapas de pré e pós processamento, ela permite que tenhamos um resultado de processamento de texto em poucas linhas.\n",
        "\n",
        "*   Todas as pipelines estão ajustadas para entradas de texto **em inglês**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Esse notebook foi modificado a partir do notebook disponibilizado pelo curso de NLP do Hugging Face, disponibilizado aqui: https://huggingface.co/learn/nlp-course/chapter1/3?fw=pt . Adicionamos comentários e modificamos os textos a serem processados.*\n"
      ],
      "metadata": {
        "id": "4ZwFWu6mbJXj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcO1uDbxYbmC"
      },
      "outputs": [],
      "source": [
        "# Essa linha instala as bibliotecas de Transformers, Datasets e Evaluate.\n",
        "# Ela deve ser executada primeiro. Depois de executá-la, você pode escolher qual dos pipelines deseja executar.\n",
        "\n",
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JUTihEAUbG7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Classificação de Sentimentos"
      ],
      "metadata": {
        "id": "OVg6hjZMzlel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Qp_xi0YbmD"
      },
      "outputs": [],
      "source": [
        "#Essa pipeline faz a classificação de sentimentos em uma sentença.\n",
        "#Dessa maneira, a frase é classificada como positiva ou negativa, de 0 a 1.\n",
        "#Portanto, se ela é classificada como POSITIVE, 0 é pouco positiva e 1 é muito positiva.\n",
        "#Da mesma maneira, se é classificada como NEGATIVE, 0 é pouco negativa e 1 é muito negativa.\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I love to learn about Transformers!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSAAhsMzYbmF"
      },
      "outputs": [],
      "source": [
        "#Podemos, também, classificar mais de uma frase ao mesmo tempo.\n",
        "#Basta colocá-las entre colchetes [], separadas por vírgulas.\n",
        "\n",
        "classifier(\n",
        "    [\"I wish this pipeline was in portuguese\", \"But ok, I'll learn anyways.\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Zero Shot Classification\n"
      ],
      "metadata": {
        "id": "8NGaYtl_zsKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deO-8vk1YbmF"
      },
      "outputs": [],
      "source": [
        "#Zeroshot Classification é quando a pipeline avalia o quanto aqueles rótulos podem classificar o texto.\n",
        "#Ela faz essa classificação do zero, sem que seja necessário fazer o fine-tuning de um modelo com dados para utilizá-lo.\n",
        "#Assim como nos casos anteriores, ela traz um número que classifica o quanto aqueles rótulos classificam o texto,\n",
        "#E essa pontuação vai de 0 (a menor) a 1 (a maior).\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"Sometimes I think about Maria do Bairro and how this telenovela impacted brazilian girls in the 90's\",\n",
        "    candidate_labels=[\"telenovela\", \"economics\", \"Brazil\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Geração de Texto"
      ],
      "metadata": {
        "id": "ONyJUYUSz00z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3lDZ-SlYbmG"
      },
      "outputs": [],
      "source": [
        "#Agora uma das funções mais em alta atualmente: a geração de texto.\n",
        "#Aqui o texto é gerado a partir do prompt, de maneira aleatória.\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"I think philosophy is...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0aspWZ4YbmH"
      },
      "outputs": [],
      "source": [
        "#Nessa linha, começamos a importar um modelo do Hugging Face - no caso, o \"distilgpt2\".\n",
        "#É possível também delimitar o tamanho máximo da resposta (max_lenght);\n",
        "#e o número máximo de sequências de frases (num_return_sequences).\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"I think philosophy is...\",\n",
        "    max_length=25,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Preenchimento"
      ],
      "metadata": {
        "id": "xTNFoHn0z5GD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oePJtSk2YbmI"
      },
      "outputs": [],
      "source": [
        "#Esse pipeline chamado \"Fill-mask\" preenche os espaços em branco na frase indicada.\n",
        "#Em \"top_k\" você consegue definir quantas possibilidades quer que sejam mostradas.\n",
        "#Atenção: aqui a palavra para a máscara é <mask>, mas diferentes modelos podem ter máscaras distintas.\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"My favorite philosopher is <mask>, because he is very smart.\", top_k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Reconhecimento de Entidades Nomeadas"
      ],
      "metadata": {
        "id": "89rfsgUxz8Pj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWdSCqGXYbmI"
      },
      "outputs": [],
      "source": [
        "#Temos nessa pipeline a NER, Named Entity Recognition.\n",
        "#Ela reconhece quais partes do texto correspondem a entidades como nomes (PER), organizações (ORG) ou lugares (LOC).\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Maria, and I live in the Bairro, working for Televisa.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Resposta"
      ],
      "metadata": {
        "id": "riNTxIIE0AlD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRtrjxx1YbmJ"
      },
      "outputs": [],
      "source": [
        "#Pipeline de Question Answering, isto é, que responde às perguntas.\n",
        "#Ela não gera conteúdo novo - a \"question\" é respondida com base no \"contexto\".\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I study?\",\n",
        "    context=\"My name is Maria and I am now studying the Transformers pipelines in the Hugging Face website. I sure recommend it.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Sumarização"
      ],
      "metadata": {
        "id": "X8u2_Qey0Nyz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG44g1x4YbmJ"
      },
      "outputs": [],
      "source": [
        "#Essa pipeline faz a sumarização do texto indicado.\n",
        "#Isto é, ela reduz um texto maior a um texto menor, mantendo as informações principais.\n",
        "#Sim, o texto é a introdução da Crítica da Razão Pura, de Kant :)\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "\n",
        "Whether the treatment of that portion of our knowledge which lies within the province of pure reason advances with that undeviating certainty which characterizes the progress of science,\n",
        "we shall be at no loss to determine. If we find those who are engaged in metaphysical pursuits, unable to come to an understanding as to the method which they ought to follow; if we find them,\n",
        "after the most elaborate preparations, invariably brought to a stand before the goal is reached, and compelled to retrace their steps and strike into fresh paths, we may then feel quite sure that\n",
        "they are far from having attained to the certainty of scientific progress and may rather be said to be merely groping about in the dark. In these circumstances we shall render an important service\n",
        "to reason if we succeed in simply indicating the path along which it must travel, in order to arrive at any results- even if it should be found necessary to abandon many of those aims which, without\n",
        "reflection, have been proposed for its attainment.\n",
        "That logic has advanced in this sure course, even from the earliest times, is apparent from the fact that, since Aristotle, it has been unable to advance a step and, thus, to all appearance has reached\n",
        "its completion. For, if some of the moderns have thought to enlarge its domain by introducing psychological discussions on the mental faculties, such as imagination and wit, metaphysical, discussions.\n",
        "on the origin of knowledge and the different kinds of certitude, according to the difference of the objects (idealism, scepticism, and so on), or anthropological discussions on prejudices, their causes\n",
        "and remedies: this attempt, on the part of these authors, only shows their ignorance of the peculiar nature of logical science. We do not enlarge but disfigure the sciences when we lose sight of their\n",
        "respective limits and allow them to run into one another. Now logic is enclosed within limits which admit of perfectly clear definition; it is a science which has for its object nothing but the exposition\n",
        "and proof of the formal laws of all thought, whether it be a priori or empirical, whatever be its origin or its object, and whatever the difficulties- natural or accidental- which it encounters in the human mind.\n",
        "\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline de Tradução"
      ],
      "metadata": {
        "id": "XynvGPw50PtT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0fM2GfBYbmJ"
      },
      "outputs": [],
      "source": [
        "#O último pipeline é de tradução.\n",
        "#Para escolher o modelo de base para tradução, o melhor modo é procurar por \"translation_en_to_fr\" como task name em modelos no Hugging Face.\n",
        "#Link: https://huggingface.co/models\n",
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Oh, je veux dire, tu voulais du portugais ! Pourquoi est-ce que je lis en français ??\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAQ_9oYYheb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}